{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning of m6A sams RNAs with Nanopore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import mkl\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from hyperopt import hp, tpe, Trials, fmin, space_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Processers\n",
    "mkl.set_num_threads(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load current data\n",
    "with open('fast5_current_m6A_sams-345_100nt.pickle', 'rb') as f:\n",
    "    current = pickle.load(f)\n",
    "print(current.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify ranges\n",
    "length = range(0,303)\n",
    "df = current[((current['sams'] == 'sams-3_E2/E3L') | (current['sams'] == 'sams-5_E2L/E3L')) & ((current['RNA'] == 'unm') | (current['RNA'] == 'm6A'))]\n",
    "\n",
    "# unm = 0, m6A = 1\n",
    "Y = df['RNA']\n",
    "Y = Y.str.replace('unm','0').str.replace('m6A','1').values\n",
    "Y = np.array(list(map(int, Y)))\n",
    "\n",
    "# current\n",
    "X = df.iloc[:,length].values\n",
    "\n",
    "# training data and test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0, test_size=0.2)\n",
    "\n",
    "# downsampling\n",
    "X_train_m6A = X_train[np.where(Y_train == 1)]\n",
    "X_train_unm = X_train[np.where(Y_train == 0)]\n",
    "X_train_unm = X_train_unm[np.random.choice(len(X_train_unm), len(X_train_m6A), replace=False)]\n",
    "X_train = np.concatenate([X_train_unm, X_train_m6A])\n",
    "Y_train = np.concatenate([np.zeros(len(X_train_m6A), dtype=int), np.ones(len(X_train_m6A), dtype=int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data set for vivo\n",
    "X_vivo3E2E3L = current[(current['sams'] == 'sams-3_E2/E3L') & (current['RNA'] == 'vivo')].iloc[:,length].values\n",
    "X_vivo3retained = current[(current['sams'] == 'sams-3_retained') & (current['RNA'] == 'vivo')].iloc[:,length].values\n",
    "X_vivo4E2E3L = current[(current['sams'] == 'sams-4_E2/E3L') & (current['RNA'] == 'vivo')].iloc[:,length].values\n",
    "X_vivo4E2LE3L = current[(current['sams'] == 'sams-4_E2L/E3L') & (current['RNA'] == 'vivo')].iloc[:,length].values\n",
    "X_vivo4retained = current[(current['sams'] == 'sams-4_retained') & (current['RNA'] == 'vivo')].iloc[:,length].values\n",
    "X_vivo5E2LE3L = current[(current['sams'] == 'sams-5_E2L/E3L') & (current['RNA'] == 'vivo')].iloc[:,length].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "# Decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# SVC\n",
    "from sklearn.svm import SVC\n",
    "# AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# GaussianNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "# LightGBM\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare classifiers by tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling?\n",
    "withScaling = {'SVM',\n",
    "              'LogisticRegression',\n",
    "              'KNeighbors',\n",
    "              'MLP'\n",
    "             }\n",
    "\n",
    "# Classifiers\n",
    "classifiers = {'GradientBoostingClassifier': GradientBoostingClassifier,\n",
    "               'XGBoost': xgb.XGBClassifier,\n",
    "               'LightGBM': lgbm.LGBMClassifier,\n",
    "               'DecisionTree': DecisionTreeClassifier,\n",
    "               'RandomForest': RandomForestClassifier,\n",
    "               'SVM': SVC,\n",
    "               'LogisticRegression': LogisticRegression,\n",
    "               'KNeighbors': KNeighborsClassifier,\n",
    "               'MLP': MLPClassifier\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Parameters\n",
    "params = {'GradientBoostingClassifier': {'learning_rate': hp.uniform('learning_rate', 0.01, 2),\n",
    "                                         'max_depth': hp.choice('max_depth', range(1,40)),\n",
    "                                         'min_samples_leaf': hp.choice('min_samples_leaf', range(1,20)),\n",
    "                                         'max_features': hp.uniform('max_features', 0.01, 1)\n",
    "                                         },\n",
    "          \n",
    "          'XGBoost': {'learning_rate': hp.uniform('learning_rate', 0.01, 2),\n",
    "                      'max_depth': hp.choice('max_depth', np.arange(1, 40, 1, dtype=int)),\n",
    "                      'min_child_weight': hp.choice('min_child_weight', np.arange(1, 10, 1, dtype=int)),\n",
    "                      'colsample_bytree': hp.uniform('colsample_bytree', 0.2, 1),\n",
    "                      'subsample': hp.uniform('subsample', 0.2, 1),\n",
    "                      'n_estimators': 100\n",
    "                     },\n",
    "          \n",
    "          'LightGBM': {'learning_rate': hp.uniform('learning_rate', 0.01, 2),\n",
    "                       'max_depth': hp.choice('max_depth', np.arange(1, 40, 1, dtype=int)),\n",
    "                       'min_child_weight': hp.choice('min_child_weight', np.arange(1, 10, 1, dtype=int)),\n",
    "                       'colsample_bytree': hp.uniform('colsample_bytree', 0.2, 1),\n",
    "                       'subsample': hp.uniform('subsample', 0.2, 1),\n",
    "                       'n_estimators': 100\n",
    "                      },\n",
    "          \n",
    "          'DecisionTree': {'max_depth': hp.choice('max_depth', np.arange(1, 40, 2, dtype=int)),\n",
    "                           'max_features': hp.choice('max_features', np.arange(1, 20, 1, dtype=int)),\n",
    "                           'min_samples_split': hp.choice('min_samples_split', np.arange(2, 20, 1, dtype=int)),\n",
    "                           'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 20, 1, dtype=int))\n",
    "                          },\n",
    "          \n",
    "          'RandomForest': {'max_depth': hp.choice('max_depth', np.arange(1, 40, 1, dtype=int)),\n",
    "                           'max_features': hp.choice('max_features', np.arange(1, 20, 1, dtype=int)),\n",
    "                           'min_samples_split': hp.choice('min_samples_split', np.arange(2, 20, 1, dtype=int)),\n",
    "                           'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 20, 1, dtype=int))\n",
    "                          },\n",
    "          \n",
    "          'SVM': {'C': hp.loguniform('C', -6, 2),\n",
    "                  'gamma': hp.loguniform('gamma', -6, 2),\n",
    "                  'kernel': hp.choice('kernel', ['linear', 'rbf', 'poly']),\n",
    "                  'cache_size': 10000\n",
    "                 },\n",
    "          \n",
    "          'LogisticRegression': {'C': hp.uniform('C', 0.00001, 1000),\n",
    "                                 'random_state': hp.choice('random_state', np.arange(1, 100, 1, dtype=int))\n",
    "                                },\n",
    "          \n",
    "          'KNeighbors': {'weights': hp.choice('weights', ['uniform','distance']),\n",
    "                         'leaf_size': hp.choice('leaf_size', np.arange(5, 50, 5, dtype=int)),\n",
    "                         'n_neighbors': hp.choice('n_neighbors', np.arange(1, 30, 1, dtype=int)),\n",
    "                         'p': hp.choice('p', np.arange(1, 3, 1, dtype=int))\n",
    "                        },\n",
    "          \n",
    "          'MLP': {'alpha': hp.loguniform('alpha', np.log(0.0001), np.log(0.9)),\n",
    "                  'hidden_layer_sizes': hp.choice('hidden_layer_sizes', np.arange(100, 1000, 50, dtype=int)),\n",
    "                  'learning_rate': hp.choice('learning_rate', ['constant','adaptive']),\n",
    "                  'activation': 'relu',\n",
    "                  'solver': 'adam'\n",
    "                 }\n",
    "         \n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting parameters\n",
    "\n",
    "# maximize accuracy score\n",
    "def objective(args):\n",
    "    \n",
    "    clf = classifier(**args)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    scoreVal = cross_validate(clf, X_train, Y_train, cv=kf)\n",
    "    return -scoreVal['test_score'].mean()\n",
    "\n",
    "\n",
    "\n",
    "# tune classifier\n",
    "def tuneClassifier(name, classifier, params):\n",
    "    \n",
    "    # scaling\n",
    "    if name in withScaling:\n",
    "        \n",
    "        # scaling\n",
    "        stdsc = StandardScaler()\n",
    "        X_train = stdsc.fit_transform(X_train)\n",
    "        X_test = stdsc.transform(X_test)\n",
    "        X_vivo3E2E3L = stdsc.transform(X_vivo3E2E3L)\n",
    "        X_vivo3retained = stdsc.transform(X_vivo3retained)\n",
    "        X_vivo4E2E3L = stdsc.transform(X_vivo4E2E3L)\n",
    "        X_vivo4E2LE3L = stdsc.transform(X_vivo4E2LE3L)\n",
    "        X_vivo4retained = stdsc.transform(X_vivo4retained)\n",
    "        X_vivo5E2LE3L = stdsc.transform(X_vivo5E2LE3L)\n",
    "        \n",
    "    \n",
    "    # save steps\n",
    "    trials = Trials()\n",
    "\n",
    "    # tuning\n",
    "    best = fmin(\n",
    "        objective,\n",
    "        params,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=100,\n",
    "        trials=trials,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # best params\n",
    "    clf = classifier(**space_eval(params, best))\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    # accuracy\n",
    "    accuracyTrain = clf.score(X_train, Y_train)\n",
    "    accuracyTest = clf.score(X_test, Y_test)\n",
    "\n",
    "    # vitro\n",
    "    predictVitroUnm = clf.predict(X_test[np.where(Y_test == 0)])\n",
    "    scoreVitroUnm = len(predictVitroUnm[predictVitroUnm == 1])/len(predictVitroUnm)\n",
    "    predictVitrom6A = clf.predict(X_test[np.where(Y_test == 1)])\n",
    "    scoreVitrom6A = len(predictVitrom6A[predictVitrom6A == 1])/len(predictVitrom6A)\n",
    "\n",
    "    # vivo\n",
    "    scoreVivo3E2E3L = np.count_nonzero(clf.predict(X_vivo3E2E3L))/len(X_vivo3E2E3L)\n",
    "    scoreVivo3retained = np.count_nonzero(clf.predict(X_vivo3retained))/len(X_vivo3retained)\n",
    "    scoreVivo4E2E3L = np.count_nonzero(clf.predict(X_vivo4E2E3L))/len(X_vivo4E2E3L)\n",
    "    scoreVivo4E2LE3L = np.count_nonzero(clf.predict(X_vivo4E2LE3L))/len(X_vivo4E2LE3L)\n",
    "    scoreVivo4retained = np.count_nonzero(clf.predict(X_vivo4retained))/len(X_vivo4retained)\n",
    "    scoreVivo5E2LE3L = np.count_nonzero(clf.predict(X_vivo5E2LE3L))/len(X_vivo5E2LE3L)\n",
    "    \n",
    "    # save the model\n",
    "    with open('Tuned_Model_' + name + '.pickle', 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "    \n",
    "    # save feature importance \n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        np.savetxt('Importance_' + name + '.csv', clf.feature_importances_, delimiter=',')\n",
    "\n",
    "    # save scores    \n",
    "    f.write('%s,'\\\n",
    "            '%s, %s, %s, %s,'\\\n",
    "            '%s, %s, %s, %s, %s, %s'\n",
    "            % (name,\n",
    "               accuracyTrain, accuracyTest, scoreVitroUnm, scoreVitrom6A,\n",
    "               scoreVivo3E2E3L, scoreVivo3retained, scoreVivo4E2E3L, scoreVivo4E2LE3L, scoreVivo4retained, scoreVivo5E2LE3L\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the accuracy and the fractions of modified bases\n",
    "out_path = base_name + '.txt'\n",
    "with open(out_path, mode='w') as f:\n",
    "\n",
    "\n",
    "    # output results    \n",
    "    f.write('Name, accuracyTrain, accuracyTest, scoreVitroUnm, scoreVitrom6A,'\\\n",
    "            'scoreVivo3E2E3L, scoreVivo3retained, scoreVivo4E2E3L, scoreVivo4E2LE3L, scoreVivo4retained, scoreVivo5E2LE3L\\n'\\\n",
    "            \n",
    "            'Size, %s, %s, %s, %s,'\\\n",
    "            '%s, %s, %s, %s, %s, %s\\n'\\\n",
    "            % (len(X_train), len(X_test), len(predictVitroUnm), len(predictVitrom6A),\n",
    "               len(X_vivo3E2E3L), len(X_vivo3retained), len(X_vivo4E2E3L), len(X_vivo4E2LE3L), len(X_vivo4retained), len(X_vivo5E2LE3L)\n",
    "            ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', mode='w') as f:\n",
    "\n",
    "    \n",
    "    # output results    \n",
    "    f.write('Name, accuracyTrain, accuracyTest, scoreVitroUnm, scoreVitrom6A\\n'\\\n",
    "            'Size, 1, 2, 3, 4\\n'\n",
    "            )\n",
    "    \n",
    "    \n",
    "    for i in range(10):\n",
    "        f.write('%s, %s, %s, %s, %s\\n' % (i, i+1, i+2, i+3, i+4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
