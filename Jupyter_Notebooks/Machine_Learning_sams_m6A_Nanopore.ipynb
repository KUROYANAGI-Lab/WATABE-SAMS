{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning of m6A sams RNAs with Nanopore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import mkl\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from hyperopt import hp, tpe, Trials, fmin, space_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processers\n",
    "mkl.set_num_threads(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(373772, 305)\n"
     ]
    }
   ],
   "source": [
    "# load current data\n",
    "with open('fast5_current_m6A_sams-345_100nt.pickle', 'rb') as f:\n",
    "    current = pickle.load(f)\n",
    "print(current.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-752f03a7740a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# training data and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# downsampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0;32m-> 2100\u001b[0;31m                                               default_test_size=0.25)\n\u001b[0m\u001b[1;32m   2101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1780\u001b[0m             \u001b[0;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m             'aforementioned parameters.'.format(n_samples, test_size,\n\u001b[0;32m-> 1782\u001b[0;31m                                                 train_size)\n\u001b[0m\u001b[1;32m   1783\u001b[0m         )\n\u001b[1;32m   1784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# specify ranges\n",
    "length = range(0,303)\n",
    "df = current[((current['sams'] == 'sams-34') | (current['sams'] == 'sams-5')) & ((current['RNA'] == 'unm') | (current['RNA'] == 'm6A'))]\n",
    "\n",
    "# unm = 0, m6A = 1\n",
    "Y = df['RNA']\n",
    "Y = Y.str.replace('unm','0').str.replace('m6A','1').values\n",
    "Y = np.array(list(map(int, Y)))\n",
    "\n",
    "# current\n",
    "X = df.iloc[:,length].values\n",
    "\n",
    "# training data and test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0, test_size=0.2)\n",
    "\n",
    "# downsampling\n",
    "X_train_m6A = X_train[np.where(Y_train == 1)]\n",
    "X_train_unm = X_train[np.where(Y_train == 0)]\n",
    "X_train_unm = X_train_unm[np.random.choice(len(X_train_unm), len(X_train_m6A), replace=False)]\n",
    "X_train = np.concatenate([X_train_unm, X_train_m6A])\n",
    "Y_train = np.concatenate([np.zeros(len(X_train_m6A), dtype=int), np.ones(len(X_train_m6A), dtype=int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data set for vivo\n",
    "X_vivo3E2E3L = current[(current['sams'] == 'sams-3 E2/E3L') & (current['RNA'] == 'vivo')].iloc[:,length].values\n",
    "X_vivo3retained = current[(current['sams'] == 'sams-3 retained') & (current['RNA'] == 'vivo')].iloc[:,length].values\n",
    "X_vivo4E2E3L = current[(current['sams'] == 'sams-4 E2/E3L') & (current['RNA'] == 'vivo')].iloc[:,length].values\n",
    "X_vivo4E2LE3L = current[(current['sams'] == 'sams-4 E2L/E3L') & (current['RNA'] == 'vivo')].iloc[:,length].values\n",
    "X_vivo4retained = current[(current['sams'] == 'sams-4 retained') & (current['RNA'] == 'vivo')].iloc[:,length].values\n",
    "X_vivo5E2LE3L = current[(current['sams'] == 'sams-5 E2L/E3L') & (current['RNA'] == 'vivo')].iloc[:,length].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuroyanagi/anaconda3/envs/keras/lib/python3.6/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# load models\n",
    "# Decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# SVC\n",
    "from sklearn.svm import SVC\n",
    "# AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# GaussianNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "# LightGBM\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare classifiers by tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "withScaling = {'SVM',\n",
    "              'LogisticRegression',\n",
    "              'KNeighbors',\n",
    "              'MLP'\n",
    "             }\n",
    "\n",
    "# Classifiers\n",
    "classifiers = {'GradientBoostingClassifier': GradientBoostingClassifier,\n",
    "               'XGBoost': xgb.XGBClassifier,\n",
    "               'LightGBM': lgbm.LGBMClassifier,\n",
    "               'DecisionTree': DecisionTreeClassifier,\n",
    "               'RandomForest': RandomForestClassifier,\n",
    "               'SVM': SVC,\n",
    "               'LogisticRegression': LogisticRegression,\n",
    "               'KNeighbors': KNeighborsClassifier,\n",
    "               'MLP': MLPClassifier\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Parameters\n",
    "params = {'GradientBoostingClassifier': {'learning_rate': hp.uniform('learning_rate', 0.01, 2),\n",
    "                                         'max_depth': hp.choice('max_depth', range(1,40)),\n",
    "                                         'min_samples_leaf': hp.choice('min_samples_leaf', range(1,20)),\n",
    "                                         'max_features': hp.uniform('max_features', 0.01, 1)\n",
    "                                         },\n",
    "          \n",
    "          'XGBoost': {'learning_rate': hp.uniform('learning_rate', 0.01, 2),\n",
    "                      'max_depth': hp.choice('max_depth', np.arange(1, 40, 1, dtype=int)),\n",
    "                      'min_child_weight': hp.choice('min_child_weight', np.arange(1, 10, 1, dtype=int)),\n",
    "                      'colsample_bytree': hp.uniform('colsample_bytree', 0.2, 1),\n",
    "                      'subsample': hp.uniform('subsample', 0.2, 1),\n",
    "                      'n_estimators': 100\n",
    "                     },\n",
    "          \n",
    "          'LightGBM': {'learning_rate': hp.uniform('learning_rate', 0.01, 2),\n",
    "                       'max_depth': hp.choice('max_depth', np.arange(1, 40, 1, dtype=int)),\n",
    "                       'min_child_weight': hp.choice('min_child_weight', np.arange(1, 10, 1, dtype=int)),\n",
    "                       'colsample_bytree': hp.uniform('colsample_bytree', 0.2, 1),\n",
    "                       'subsample': hp.uniform('subsample', 0.2, 1),\n",
    "                       'n_estimators': 100\n",
    "                      },\n",
    "          \n",
    "          'DecisionTree': {'max_depth': hp.choice('max_depth', np.arange(1, 40, 2, dtype=int)),\n",
    "                           'max_features': hp.choice('max_features', np.arange(1, 20, 1, dtype=int)),\n",
    "                           'min_samples_split': hp.choice('min_samples_split', np.arange(2, 20, 1, dtype=int)),\n",
    "                           'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 20, 1, dtype=int))\n",
    "                          },\n",
    "          \n",
    "          'RandomForest': {'max_depth': hp.choice('max_depth', np.arange(1, 40, 1, dtype=int)),\n",
    "                           'max_features': hp.choice('max_features', np.arange(1, 20, 1, dtype=int)),\n",
    "                           'min_samples_split': hp.choice('min_samples_split', np.arange(2, 20, 1, dtype=int)),\n",
    "                           'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 20, 1, dtype=int))\n",
    "                          },\n",
    "          \n",
    "          'SVM': {'C': hp.loguniform('C', -6, 2),\n",
    "                  'gamma': hp.loguniform('gamma', -6, 2),\n",
    "                  'kernel': hp.choice('kernel', ['linear', 'rbf', 'poly']),\n",
    "                  'cache_size': 10000\n",
    "                 },\n",
    "          \n",
    "          'LogisticRegression': {'C': hp.uniform('C', 0.00001, 1000),\n",
    "                                 'random_state': hp.choice('random_state', np.arange(1, 100, 1, dtype=int))\n",
    "                                },\n",
    "          \n",
    "          'KNeighbors': {'weights': hp.choice('weights', ['uniform','distance']),\n",
    "                         'leaf_size': hp.choice('leaf_size', np.arange(5, 50, 5, dtype=int)),\n",
    "                         'n_neighbors': hp.choice('n_neighbors', np.arange(1, 30, 1, dtype=int)),\n",
    "                         'p': hp.choice('p', np.arange(1, 3, 1, dtype=int))\n",
    "                        },\n",
    "          \n",
    "          'MLP': {'alpha': hp.loguniform('alpha', np.log(0.0001), np.log(0.9)),\n",
    "                  'hidden_layer_sizes': hp.choice('hidden_layer_sizes', np.arange(100, 1000, 50, dtype=int)),\n",
    "                  'learning_rate': hp.choice('learning_rate', ['constant','adaptive']),\n",
    "                  'activation': 'relu',\n",
    "                  'solver': 'adam'\n",
    "                 }\n",
    "         \n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting parameters\n",
    "\n",
    "# maximize accuracy score\n",
    "def objective(args):\n",
    "    \n",
    "    clf = classifier(**args)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    scoreVal = cross_validate(clf, X_train, Y_train, cv=kf)\n",
    "    return -scoreVal['test_score'].mean()\n",
    "\n",
    "\n",
    "\n",
    "# tune classifier\n",
    "def tuneClassifier(name, classifier, params):\n",
    "    \n",
    "    # scaling\n",
    "    if name in withScaling:\n",
    "        \n",
    "        # scaling\n",
    "        stdsc = StandardScaler()\n",
    "        X_train = stdsc.fit_transform(X_train)\n",
    "        X_test = stdsc.transform(X_test)\n",
    "        X_vivo3E2E3L = stdsc.transform(X_vivo3E2E3L)\n",
    "        X_vivo3retained = stdsc.transform(X_vivo3retained)\n",
    "        X_vivo4E2E3L = stdsc.transform(X_vivo4E2E3L)\n",
    "        X_vivo4E2LE3L = stdsc.transform(X_vivo4E2LE3L)\n",
    "        X_vivo4retained = stdsc.transform(X_vivo4retained)\n",
    "        X_vivo5E2LE3L = stdsc.transform(X_vivo5E2LE3L)\n",
    "        \n",
    "    \n",
    "    # save steps\n",
    "    trials = Trials()\n",
    "\n",
    "    # tuning\n",
    "    best = fmin(\n",
    "        objective,\n",
    "        params,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=100,\n",
    "        trials=trials,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # best params\n",
    "    clf = classifier(**space_eval(params, best))\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    # accuracy\n",
    "    accuracyTrain = clf.score(X_train, Y_train)\n",
    "    accuracyTest = clf.score(X_test, Y_test)\n",
    "\n",
    "    # vitro\n",
    "    predictVitroUnm = clf.predict(X_test[np.where(Y_test == 0)])\n",
    "    scoreVitroUnm = len(predictVitroUnm[predictVitroUnm == 1])/len(predictVitroUnm)\n",
    "    predictVitrom6A = clf.predict(X_test[np.where(Y_test == 1)])\n",
    "    scoreVitrom6A = len(predictVitrom6A[predictVitrom6A == 1])/len(predictVitrom6A)\n",
    "\n",
    "    # vivo\n",
    "    scoreVivo3E2E3L = np.count_nonzero(clf.predict(X_vivo3E2E3L))/len(X_vivo3E2E3L)\n",
    "    scoreVivo3retained = np.count_nonzero(clf.predict(X_vivo3retained))/len(X_vivo3retained)\n",
    "    scoreVivo4E2E3L = np.count_nonzero(clf.predict(X_vivo4E2E3L))/len(X_vivo4E2E3L)\n",
    "    scoreVivo4E2LE3L = np.count_nonzero(clf.predict(X_vivo4E2LE3L))/len(X_vivo4E2LE3L)\n",
    "    scoreVivo4retained = np.count_nonzero(clf.predict(X_vivo4retained))/len(X_vivo4retained)\n",
    "    scoreVivo5E2LE3L = np.count_nonzero(clf.predict(X_vivo5E2LE3L))/len(X_vivo5E2LE3L)\n",
    "    \n",
    "    # save the model\n",
    "    with open('Tuned_Model_' + name + '.pickle', 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "    \n",
    "    # save feature importance\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        np.savetxt('Importance_' + name + '.csv', clf.feature_importances_, delimiter=',')\n",
    "\n",
    "    # save scores    \n",
    "    f.write('%s,'\\\n",
    "            '%s, %s, %s, %s,'\\\n",
    "            '%s, %s, %s, %s, %s, %s'\n",
    "            % (name,\n",
    "               accuracyTrain, accuracyTest, scoreVitroUnm, scoreVitrom6A,\n",
    "               scoreVivo3E2E3L, scoreVivo3retained, scoreVivo4E2E3L, scoreVivo4E2LE3L, scoreVivo4retained, scoreVivo5E2LE3L\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the accuracy and the fractions of modified bases\n",
    "out_path = base_name + '.txt'\n",
    "with open(out_path, mode='w') as f:\n",
    "\n",
    "\n",
    "    # output results    \n",
    "    f.write('Name, accuracyTrain, accuracyTest, scoreVitroUnm, scoreVitrom6A,'\\\n",
    "            'scoreVivo3E2E3L, scoreVivo3retained, scoreVivo4E2E3L, scoreVivo4E2LE3L, scoreVivo4retained, scoreVivo5E2LE3L\\n'\\\n",
    "            \n",
    "            'Size, %s, %s, %s, %s,'\\\n",
    "            '%s, %s, %s, %s, %s, %s\\n'\\\n",
    "            % (len(X_train), len(X_test), len(predictVitroUnm), len(predictVitrom6A),\n",
    "               len(X_vivo3E2E3L), len(X_vivo3retained), len(X_vivo4E2E3L), len(X_vivo4E2LE3L), len(X_vivo4retained), len(X_vivo5E2LE3L)\n",
    "            ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', mode='w') as f:\n",
    "\n",
    "    \n",
    "    # output results    \n",
    "    f.write('Name, accuracyTrain, accuracyTest, scoreVitroUnm, scoreVitrom6A\\n'\\\n",
    "            'Size, 1, 2, 3, 4\\n'\n",
    "            )\n",
    "    \n",
    "    \n",
    "    for i in range(10):\n",
    "        f.write('%s, %s, %s, %s, %s\\n' % (i, i+1, i+2, i+3, i+4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare classifiers by tuned parameters and scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "stdsc = StandardScaler()\n",
    "X_train = stdsc.fit_transform(X_train)\n",
    "X_test = stdsc.transform(X_test)\n",
    "\n",
    "X_unmlong3b = stdsc.transform(X_unmlong3b)\n",
    "X_unmlong3c = stdsc.transform(X_unmlong3c)\n",
    "X_unmlong4b = stdsc.transform(X_unmlong4b)\n",
    "X_unmlong4c = stdsc.transform(X_unmlong4c)\n",
    "X_unmlong4d = stdsc.transform(X_unmlong4d)\n",
    "\n",
    "X_vivo3b = stdsc.transform(X_vivo3b)\n",
    "X_vivo3c = stdsc.transform(X_vivo3c)\n",
    "X_vivo4b = stdsc.transform(X_vivo4b)\n",
    "X_vivo4c = stdsc.transform(X_vivo4c)\n",
    "X_vivo4d = stdsc.transform(X_vivo4d)\n",
    "X_vivo5b = stdsc.transform(X_vivo5b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fitting parameters\n",
    "# file name\n",
    "base_name = 'Hyperopt_' + name + '_m6A_Nanopore_current_100nt_sams-3b5b'\n",
    "\n",
    "# function to minimize\n",
    "def objective(args):\n",
    "    clf = classifier(**args)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    scoreTest = clf.score(X_test,Y_test)\n",
    "    return -1*scoreTest\n",
    "\n",
    "# save steps\n",
    "trials = Trials()\n",
    "\n",
    "# tuning\n",
    "best = fmin(\n",
    "    objective,\n",
    "    params,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# best params\n",
    "clf = classifier(**space_eval(params, best))\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# save model\n",
    "with open(base_name + '.pickle', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "    \n",
    "    \n",
    "# output scores\n",
    "out_path = base_name + '.txt'\n",
    "with open(out_path, mode='w') as f:\n",
    "\n",
    "    \n",
    "    # training set\n",
    "    accuracyTrain = clf.score(X_train,Y_train)\n",
    "    \n",
    "    \n",
    "    # test set\n",
    "    accuracyTest = clf.score(X_test,Y_test)\n",
    "    \n",
    "    predictTestUnm = clf.predict(X_test[np.where(Y_test == 0)])\n",
    "    scoreTestUnm = len(predictTestUnm[predictTestUnm == 1])/len(predictTestUnm)\n",
    "    \n",
    "    predictTestm6A = clf.predict(X_test[np.where(Y_test == 1)])\n",
    "    scoreTestm6A = len(predictTestm6A[predictTestm6A == 1])/len(predictTestm6A)\n",
    "    \n",
    "    \n",
    "    # unmodified long\n",
    "    scoreUnmlong3b = np.count_nonzero(clf.predict(X_unmlong3b))/len(X_unmlong3b)\n",
    "    scoreUnmlong3c = np.count_nonzero(clf.predict(X_unmlong3c))/len(X_unmlong3c)\n",
    "    scoreUnmlong4b = np.count_nonzero(clf.predict(X_unmlong4b))/len(X_unmlong4b)\n",
    "    scoreUnmlong4c = np.count_nonzero(clf.predict(X_unmlong4c))/len(X_unmlong4c)\n",
    "    scoreUnmlong4d = np.count_nonzero(clf.predict(X_unmlong4d))/len(X_unmlong4d)\n",
    "\n",
    "\n",
    "    # vivo\n",
    "    scoreVivo3b = np.count_nonzero(clf.predict(X_vivo3b))/len(X_vivo3b)\n",
    "    scoreVivo3c = np.count_nonzero(clf.predict(X_vivo3c))/len(X_vivo3c)\n",
    "    scoreVivo4b = np.count_nonzero(clf.predict(X_vivo4b))/len(X_vivo4b)\n",
    "    scoreVivo4c = np.count_nonzero(clf.predict(X_vivo4c))/len(X_vivo4c)\n",
    "    scoreVivo4d = np.count_nonzero(clf.predict(X_vivo4d))/len(X_vivo4d)\n",
    "    scoreVivo5b = np.count_nonzero(clf.predict(X_vivo5b))/len(X_vivo5b)\n",
    "    \n",
    "    \n",
    "    # write results\n",
    "    label = 'accuracyTrain,accuracyTest,scoreTestUnm,scoreTestm6A,scoreUnmlong3b,scoreUnmlong3c,'\\\n",
    "            'scoreUnmlong4b,scoreUnmlong4c,scoreUnmlong4d,scoreVivo3b,scoreVivo3c,scoreVivo4b,scoreVivo4c,scoreVivo4d,scoreVivo5b'\n",
    "    \n",
    "    f.write('Name,%s\\n'\\\n",
    "            \n",
    "            'Size,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s\\n'\\\n",
    "            \n",
    "            'Score,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s' \n",
    "            \n",
    "            % (label,\n",
    "               \n",
    "               len(X_train), len(X_test), len(predictTestUnm), len(predictTestm6A),\n",
    "               len(X_unmlong3b), len(X_unmlong3c), len(X_unmlong4b), len(X_unmlong4c), len(X_unmlong4d),\n",
    "               len(X_vivo3b), len(X_vivo3c), len(X_vivo4b), len(X_vivo4c), len(X_vivo4d), len(X_vivo5b),\n",
    "               \n",
    "               accuracyTrain, accuracyTest, scoreTestUnm, scoreTestm6A,\n",
    "               scoreUnmlong3b, scoreUnmlong3c, scoreUnmlong4b, scoreUnmlong4c, scoreUnmlong4d,\n",
    "               scoreVivo3b, scoreVivo3c, scoreVivo4b, scoreVivo4c, scoreVivo4d, scoreVivo5b\n",
    "            ))\n",
    "\n",
    "# importance from Gradient boosting model\n",
    "if hasattr(clf, 'feature_importances_'):\n",
    "    np.savetxt('Importance_' + base_name + '.csv', clf.feature_importances_, delimiter=',')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare classifiers by default parameters and scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set classifiers\n",
    "names = [\n",
    "        'Decision Tree',\n",
    "        'Random Forest', \n",
    "        'Logistic Regression',\n",
    "        'K-Nearest Neighbor',\n",
    "        'SVM',\n",
    "        'Adaptive Boosting',\n",
    "        'Gradient Boosting',\n",
    "        'Gaussian Naive Bayes',\n",
    "        'Linear Discriminant Analysis',\n",
    "        'Quadratic Discriminant Analysis',\n",
    "        'Multilayer Perceptron',\n",
    "        'XGBoost',\n",
    "        'LightGBM'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "                DecisionTreeClassifier(),\n",
    "                RandomForestClassifier(),\n",
    "                LogisticRegression(),\n",
    "                KNeighborsClassifier(),\n",
    "                SVC(),\n",
    "                AdaBoostClassifier(),\n",
    "                GradientBoostingClassifier(),\n",
    "                GaussianNB(),\n",
    "                LinearDiscriminantAnalysis(),\n",
    "                QuadraticDiscriminantAnalysis(),\n",
    "                MLPClassifier(),\n",
    "                xgb.XGBClassifier(),\n",
    "                lgbm.LGBMClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuroyanagi/anaconda3/envs/keras/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuroyanagi/anaconda3/envs/keras/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression done\n",
      "K-Nearest Neighbor done\n",
      "SVM done\n",
      "Adaptive Boosting done\n",
      "Gradient Boosting done\n",
      "Gaussian Naive Bayes done\n",
      "Linear Discriminant Analysis done\n",
      "Quadratic Discriminant Analysis done\n",
      "Multilayer Perceptron done\n",
      "XGBoost done\n",
      "LightGBM done\n"
     ]
    }
   ],
   "source": [
    "# compare classifiers\n",
    "out_path = 'sklearn_compareClassifiers_m6A_Nanopore_current_sams-3b5b_100nt.txt'\n",
    "with open(out_path, mode='w') as f:\n",
    "    \n",
    "\n",
    "    # loop classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        \n",
    "        \n",
    "        # fitting\n",
    "        clf = clf.fit(X_train,Y_train)\n",
    "        \n",
    "        \n",
    "        # training set\n",
    "        accuracyTrain = clf.score(X_train,Y_train)\n",
    "\n",
    "\n",
    "        # test set\n",
    "        accuracyTest = clf.score(X_test,Y_test)\n",
    "\n",
    "        predictTestUnm = clf.predict(X_test[np.where(Y_test == 0)])\n",
    "        scoreTestUnm = len(predictTestUnm[predictTestUnm == 1])/len(predictTestUnm)\n",
    "\n",
    "        predictTestm6A = clf.predict(X_test[np.where(Y_test == 1)])\n",
    "        scoreTestm6A = len(predictTestm6A[predictTestm6A == 1])/len(predictTestm6A)\n",
    "\n",
    "\n",
    "        # unmodified long\n",
    "        scoreUnmlong3b = np.count_nonzero(clf.predict(X_unmlong3b))/len(X_unmlong3b)\n",
    "        scoreUnmlong3c = np.count_nonzero(clf.predict(X_unmlong3c))/len(X_unmlong3c)\n",
    "        scoreUnmlong4b = np.count_nonzero(clf.predict(X_unmlong4b))/len(X_unmlong4b)\n",
    "        scoreUnmlong4c = np.count_nonzero(clf.predict(X_unmlong4c))/len(X_unmlong4c)\n",
    "        scoreUnmlong4d = np.count_nonzero(clf.predict(X_unmlong4d))/len(X_unmlong4d)\n",
    "\n",
    "\n",
    "        # vivo\n",
    "        scoreVivo3b = np.count_nonzero(clf.predict(X_vivo3b))/len(X_vivo3b)\n",
    "        scoreVivo3c = np.count_nonzero(clf.predict(X_vivo3c))/len(X_vivo3c)\n",
    "        scoreVivo4b = np.count_nonzero(clf.predict(X_vivo4b))/len(X_vivo4b)\n",
    "        scoreVivo4c = np.count_nonzero(clf.predict(X_vivo4c))/len(X_vivo4c)\n",
    "        scoreVivo4d = np.count_nonzero(clf.predict(X_vivo4d))/len(X_vivo4d)\n",
    "        scoreVivo5b = np.count_nonzero(clf.predict(X_vivo5b))/len(X_vivo5b)\n",
    "\n",
    "\n",
    "        # write results\n",
    "        f.write('%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s\\n' \n",
    "                % (name, accuracyTrain, accuracyTest, scoreTestUnm, scoreTestm6A,\n",
    "                   scoreUnmlong3b, scoreUnmlong3c, scoreUnmlong4b, scoreUnmlong4c, scoreUnmlong4d,\n",
    "                   scoreVivo3b, scoreVivo3c, scoreVivo4b, scoreVivo4c, scoreVivo4d, scoreVivo5b))\n",
    "        \n",
    "        # tracking\n",
    "        print(name + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
